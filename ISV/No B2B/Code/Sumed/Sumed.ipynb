{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2022\n",
    "week = 8\n",
    "#path = r'C:\\Users\\jshernandezm\\OneDrive - genommalabinternacional\\Info_POS_clientes\\Sell Out - No B2b\\Sumed'\n",
    "path = r'C:\\Users\\amartinezgo\\genommalabinternacional\\Francisco Jose Delfino - Info_POS_clientes\\Sell Out - No B2b\\Sumed'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import pyodbc\n",
    "import shutil\n",
    "import os\n",
    "from openpyxl import load_workbook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conexiones y querys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn1 = pyodbc.connect('Driver={SQL Server};'\n",
    "                     'Server=SFEDWH01;'\n",
    "                     'Database=Gnm_DWH;'\n",
    "                     'Trusted_Connection=yes;')\n",
    "\n",
    "conn2 = pyodbc.connect('Driver={SQL Server};'\n",
    "                     'Server=SFEDWH01;'\n",
    "                     'Database=Gnm_MasterOp;'\n",
    "                     'Trusted_Connection=yes;')\n",
    "\n",
    "query_dates = '''\n",
    "                SELECT TmpFecha\n",
    "                      ,TmpSemanaAnioGenomma\n",
    "                      ,TmpAnioSemanaGenomma\n",
    "\n",
    "                  FROM dbo.Dim_Tiempo where TmpDiaSemana = 7 order by TmpID\n",
    "'''\n",
    "\n",
    "query_nombres = '''\n",
    "                SELECT DISTINCT ProPstCodBarras, ProPstNombre\n",
    "                  FROM dbo.vw_EstructuraProductosTotalPaises\n",
    "                  WHERE País = 'Argentina';\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importar Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '{0}_{1}_Sumed_SO.xlsx'.format(year, str(week).zfill(2))\n",
    "file_names = [filename]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read SQL and drop duplicates\n",
    "nombres = pd.read_sql(query_nombres,conn2)\n",
    "nombres.drop_duplicates(subset=['ProPstCodBarras'],inplace=True)\n",
    "nombres.columns = ['EAN o UPC Genomma','Desc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listo archivo 2022_08_Sumed_SO.xlsx\n"
     ]
    }
   ],
   "source": [
    "dates = pd.read_sql(query_dates,conn1)\n",
    "df_all = pd.DataFrame()\n",
    "files_to_check = []\n",
    "\n",
    "for file in file_names:\n",
    "    #Save year and week from file name\n",
    "    year = int(file.split('_')[0])\n",
    "    week = int(file.split('_')[1])\n",
    "\n",
    "    df = pd.read_excel(path + '\\\\' + file, header=1)\n",
    "    #Check if the file has 3 or 4 columns\n",
    "    if len(list(df.columns)) == 4:\n",
    "        df.columns = ['EAN','DESC','ALIAS','CANTIDAD']\n",
    "    else:\n",
    "        df.columns = ['EAN','DESC','CANTIDAD']\n",
    "    #Drop last row if it has the total units\n",
    "    if df.loc[df.iloc[-1:,-1:].index,'CANTIDAD'].values == df.iloc[:-1]['CANTIDAD'].sum():\n",
    "        df.drop(df.iloc[-1:,-1:].index,inplace=True)\n",
    "\n",
    "    df.fillna(value={'EAN':0},inplace=True)\n",
    "\n",
    "    data_final = pd.DataFrame()\n",
    "    #Set values for distinct columns\n",
    "    data_final['Unidades'] = df['CANTIDAD']\n",
    "    data_final['Fecha_Venta'] = dates[(dates['TmpAnioSemanaGenomma'] == year) & (dates['TmpSemanaAnioGenomma'] == week)]['TmpFecha'].unique()[0]\n",
    "    data_final['Fecha_Venta'] = data_final['Fecha_Venta'].dt.date\n",
    "    data_final['Cadena'] = 'Sumed'\n",
    "    data_final['Cod_Prod de la Cadena'] = df['EAN'].astype('int64')\n",
    "    data_final['EAN o UPC Genomma'] = df['EAN'].astype('int64')\n",
    "    data_final['Descripcion_Prod'] = df['DESC']\n",
    "    #Store code manually inserted\n",
    "    data_final['Cod_Local'] = '1'\n",
    "    data_final['Descripcion_Local'] = 'Sumed Local Generico'\n",
    "    data_final = pd.merge(data_final,nombres, on='EAN o UPC Genomma', how='left')\n",
    "    #Rearrange dataframe and save it\n",
    "    #data_final = data_final[['Fecha_Venta','Cadena','Cod_Prod de la Cadena','EAN o UPC Genomma','Desc','Cod_Local','Descripcion_Local','Unidades']]\n",
    "    data_final = data_final[['Fecha_Venta','Cadena','Cod_Prod de la Cadena','EAN o UPC Genomma','Descripcion_Prod','Cod_Local','Descripcion_Local','Unidades']]\n",
    "    data_final.dropna(subset=['Unidades'],inplace=True)\n",
    "    #data_final['Desc'] = data_final['Desc'].apply(lambda x: x.strip())\n",
    "    data_final['Descripcion_Local'] = data_final['Descripcion_Local'].apply(lambda x: x.strip())\n",
    "    df_all = pd.concat([df_all,data_final])\n",
    "    print('Listo archivo ' + file)\n",
    "        \n",
    "\n",
    "df_all.reset_index(drop=True,inplace=True)\n",
    "#Check for missing EAN\n",
    "if df_all[df_all['EAN o UPC Genomma']==0].shape[0] > 0:\n",
    "    print('Revisar archivo, producto sin EAN...')\n",
    "\n",
    "#CODIGO DE ABAJO NO SIRVE SI SE CORRE UNA SEMANA ES PARA LLENAR LOS EAN DEL HISTORICO...\n",
    "# if df_all[df_all['EAN o UPC Genomma'] == 0].shape[0] > 0:\n",
    "#     df_all['key'] = df_all['EAN o UPC Genomma'].astype(str) + '-' + df_all['Descripcion_Prod'].astype(str) \n",
    "#     df_aux = df_all[df_all['EAN o UPC Genomma']==0].copy()\n",
    "#     df_aux['EAN o UPC Genomma'] = df_aux['Descripcion_Prod'].apply(lambda x: int(df_all[df_all['Descripcion_Prod'] == x]['key'].value_counts().index[0].split('-')[0]) if int(df_all[df_all['Descripcion_Prod'] == x]['key'].value_counts().index[0].split('-')[0]) != 0 else int(df_all[df_all['Descripcion_Prod'] == x]['key'].value_counts().index[2].split('-')[0]))\n",
    "#     df_all.drop(df_aux.index,axis=0,inplace=True)\n",
    "#     df_all = pd.concat([df_all,df_aux])\n",
    "\n",
    "# df_all = pd.merge(df_all,nombres, on='EAN o UPC Genomma', how='left')\n",
    "# df_all['Cod_Prod de la Cadena'] = df_all['EAN o UPC Genomma']\n",
    "# df_all =  df_all[['Fecha_Venta','Cadena','Cod_Prod de la Cadena','EAN o UPC Genomma','Descripcion_Prod','Desc','Cod_Local','Descripcion_Local','Unidades']]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fecha_Venta              0\n",
       "Cadena                   0\n",
       "Cod_Prod de la Cadena    0\n",
       "EAN o UPC Genomma        0\n",
       "Descripcion_Prod         0\n",
       "Cod_Local                0\n",
       "Descripcion_Local        0\n",
       "Unidades                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check if if there's a columns with missing values\n",
    "df_all.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exportación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_layout(filename, df, sellout=True):\n",
    "    writer = pd.ExcelWriter(filename, engine='openpyxl', mode='a')\n",
    "    writer.book = load_workbook(filename)\n",
    "    writer.sheets = {ws.title:ws for ws in writer.book.worksheets}\n",
    "    if sellout == True:\n",
    "        df.to_excel(writer, sheet_name='Ventas', startcol=1, startrow=18, index=False, header=None)\n",
    "    else:\n",
    "        df.to_excel(writer, sheet_name='Stock', startcol=1, startrow=18, index=False, header=None)\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toma el layout de ISV y crea la carpeta correspondiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = '../../../../1Data/2Catalogue/toISV/Layout/Formato No B2B Orig.xlsx'\n",
    "new_folder = '../../../../1Data/2Catalogue/toISV/{0}/S{1}/'.format(year, str(week).zfill(2))\n",
    "\n",
    "if not os.path.exists(new_folder):\n",
    "    os.mkdir(new_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "filename = 'Formato No B2B SUMED Sem ' + str(week).zfill(2)\n",
    "path_export = new_folder + '/' + filename +'.xlsx'\n",
    "shutil.copy(original, path_export)\n",
    "write_layout(path_export, df_all, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
