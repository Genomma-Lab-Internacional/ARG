{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2022\n",
    "week = 5\n",
    "#path_so = r'C:\\Users\\jshernandezm\\OneDrive - genommalabinternacional\\Info_POS_clientes\\Sell Out - No B2b\\Disval'\n",
    "path_so = r'C:\\Users\\amartinezgo\\genommalabinternacional\\Francisco Jose Delfino - Info_POS_clientes\\Sell Out - No B2b\\Disval'\n",
    "#path_inv = r'C:\\Users\\jshernandezm\\OneDrive - genommalabinternacional\\Info_POS_clientes\\Stocks\\{0}\\Semana {1}'\n",
    "path_inv = r'C:\\Users\\amartinezgo\\genommalabinternacional\\Francisco Jose Delfino - Info_POS_clientes\\Stocks\\{0}\\Semana {1}'\n",
    "path_inv = path_inv.format(year, str(week).zfill(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import pyodbc\n",
    "import shutil\n",
    "import os\n",
    "from openpyxl import load_workbook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weekly data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connections to DWH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn1 = pyodbc.connect('Driver={SQL Server};'\n",
    "                     'Server=SFEDWH01;'\n",
    "                     'Database=Gnm_DWH;'\n",
    "                     'Trusted_Connection=yes;')\n",
    "\n",
    "conn2 = pyodbc.connect('Driver={SQL Server};'\n",
    "                     'Server=SFEDWH01;'\n",
    "                     'Database=Gnm_MasterOp;'\n",
    "                     'Trusted_Connection=yes;')\n",
    "\n",
    "query_days = '''SELECT TmpFecha\n",
    "                FROM Gnm_DWH.dbo.Dim_Tiempo\n",
    "                WHERE TmpAnioSemanaGenomma = {0} AND TmpSemanaAnioGenomma = {1}'''\n",
    "\n",
    "query_sucs = '''SELECT DISTINCT SUC.SucCodCliente, SUC.SucId\n",
    "                    FROM (SELECT DISTINCT PaisNombre, CadID FROM Gnm_MasterOp.dbo.vw_EstructuraClientesSegPTVTotal\n",
    "                    WHERE PaisNombre = 'Argentina') AS CLIE\n",
    "                LEFT JOIN (\n",
    "                    SELECT DISTINCT SucId, SucCodCliente, CadId FROM Gnm_MasterOp.dbo.vw_EstructuraSucursalesTotal) AS SUC\n",
    "                ON CLIE.CadID = SUC.CadID \n",
    "                '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stocks\n",
    "\n",
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = '{0}_{1}_Disval_INV.txt'\n",
    "\n",
    "df_stock = pd.DataFrame()\n",
    "# Dates\n",
    "df_days = pd.read_sql(query_days.format(year, week), conn1)\n",
    "\n",
    "# Import data\n",
    "df = pd.read_csv(path_inv + '\\\\' + file_name.format(year, str(week).zfill(2)), header=None)\n",
    "\n",
    "# Assign date into the dataframe\n",
    "df['Fecha_Stock'] = df_days['TmpFecha'].max()\n",
    "df_stock = pd.concat([df_stock, df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatting data stocks\n",
    "df_stock.rename(dict(zip(range(5), ['Cod_Cliente', 'EAN o UPC Genomma', 'Descripcion_Prod', 'Descripcion_Local', 'Unidades'])), axis=1, inplace=True)\n",
    "df_stock['Cadena'] = 'Disval'\n",
    "df_stock['Cod_Prod'] = df_stock['EAN o UPC Genomma']\n",
    "df_stock['Cod_Local'] = '89310'\n",
    "data_stock = df_stock[['Fecha_Stock', 'Cadena', 'Cod_Prod', 'EAN o UPC Genomma', 'Descripcion_Prod', 'Cod_Local', 'Descripcion_Local', 'Unidades']].copy()\n",
    "data_stock = data_stock[~data_stock['EAN o UPC Genomma'].isin([999999, 9999999999999])].copy()\n",
    "# Order columns\n",
    "final_stock = data_stock[['Fecha_Stock', 'Cadena', 'Cod_Prod', 'EAN o UPC Genomma', 'Descripcion_Prod', 'Cod_Local', 'Descripcion_Local', 'Unidades']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fecha_Stock          0\n",
       "Cadena               0\n",
       "Cod_Prod             0\n",
       "EAN o UPC Genomma    0\n",
       "Descripcion_Prod     0\n",
       "Cod_Local            0\n",
       "Descripcion_Local    0\n",
       "Unidades             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_stock.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sell Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select elements in intersection\n",
    "def dates_repeted(dates, new_dates):\n",
    "    pattern = set(dates)\n",
    "    return [x for x in new_dates if x in dates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date to str\n",
    "def date_to_str(date):\n",
    "    try:\n",
    "        return date.strftime('%Y-%m-%d')\n",
    "    except:\n",
    "        return date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# The SO data is accumulated, so we import several dates\n",
    "df_so = pd.DataFrame(columns=range(9))\n",
    "for year, week in [(year, w) for w in range(week - 4, week + 1)]: \n",
    "    try:\n",
    "        # Search the files in differents locations\n",
    "        file_name = '{0}_{1}_Disval_SO.txt'\n",
    "        df = pd.read_csv(path_so + '\\\\' + file_name.format(year, str(week).zfill(2)), header=None)\n",
    "        # Clean date\n",
    "        df[5] = df[5].map(date_to_str)\n",
    "        # Get the unique days\n",
    "        dr = dates_repeted(df_so[5].unique(), df[5].unique())\n",
    "        if len(dr) > 0:\n",
    "            df_so = df_so[~df_so[5].isin(dr)].copy()\n",
    "        df_so = pd.concat([df_so, df], axis=0)\n",
    "    except:\n",
    "        print('Ojo con el archivo ' + str(year) + ' - ' + str(week).zfill(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatting sell out columns\n",
    "df_so['Fecha'] = df_so[5].apply(lambda x: datetime.strptime(x, '%Y-%m-%d'))\n",
    "# Filter the specific week\n",
    "df_so = df_so[df_so['Fecha'].isin(df_days['TmpFecha'].tolist())].copy()\n",
    "df_so.rename({6:'EAN o UPC Genomma', 7:'Descripcion_Local', 8:'Unidades'}, axis=1, inplace=True)\n",
    "df_so['Cadena'] = 'Disval'\n",
    "df_so['Cod_Prod'] = df_so['EAN o UPC Genomma']\n",
    "df_so['Cod_Local'] = '89310'\n",
    "data_so = df_so[['Fecha', 'Cadena', 'Cod_Prod', 'EAN o UPC Genomma', 'Cod_Local', 'Descripcion_Local', 'Unidades']].copy()\n",
    "# Filter EAN\n",
    "data_so = data_so[~data_so['EAN o UPC Genomma'].isin([999999, 9999999999999])].copy()\n",
    "# Merge with stock's Descripcion\n",
    "aux = data_stock[['EAN o UPC Genomma', 'Descripcion_Prod']]\n",
    "data_so = data_so.merge(aux.drop_duplicates(), on='EAN o UPC Genomma', how='left')\n",
    "# Order columns\n",
    "final_so = data_so[['Fecha', 'Cadena', 'Cod_Prod', 'EAN o UPC Genomma', 'Descripcion_Prod', 'Cod_Local', 'Descripcion_Local', 'Unidades']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fecha                0\n",
       "Cadena               0\n",
       "Cod_Prod             0\n",
       "EAN o UPC Genomma    0\n",
       "Descripcion_Prod     0\n",
       "Cod_Local            0\n",
       "Descripcion_Local    0\n",
       "Unidades             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_so.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export to layout file\n",
    "def write_layout(filename, df, sellout=True):\n",
    "    writer = pd.ExcelWriter(filename, engine='openpyxl', mode='a')\n",
    "    writer.book = load_workbook(filename)\n",
    "    writer.sheets = {ws.title:ws for ws in writer.book.worksheets}\n",
    "    if sellout == True:\n",
    "        df.to_excel(writer, sheet_name='Ventas', startcol=1, startrow=18, index=False, header=None)\n",
    "    else:\n",
    "        df.to_excel(writer, sheet_name='Stock', startcol=1, startrow=18, index=False, header=None)\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toma el layout de ISV y crea la carpeta correspondiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = '../../../../1Data/2Catalogue/toISV/Layout/Formato No B2B Orig.xlsx'\n",
    "new_folder = '../../../../1Data/2Catalogue/toISV/{0}/S{1}'.format(year, str(week).zfill(2))\n",
    "\n",
    "#Create a new directory\n",
    "if not os.path.exists(new_folder):\n",
    "    os.mkdir(new_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.61 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "filename = 'Formato No B2B Disval Sem {}'.format(str(week).zfill(2))\n",
    "path_export = new_folder + '/' + filename +'.xlsx'\n",
    "\n",
    "## Copy layout with name <filename>\n",
    "shutil.copy(original, path_export)\n",
    "\n",
    "## Export in different sheets\n",
    "write_layout(path_export, final_so, True)\n",
    "write_layout(path_export, final_stock, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "304.475px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
